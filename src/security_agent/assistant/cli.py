"""Interactive CLI chat for the AI security assistant."""

from __future__ import annotations

from langchain_core.messages import HumanMessage

from security_agent.assistant.graph import build_assistant_graph


WELCOME_BANNER = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘            ğŸ›¡ï¸  SafeLine AI Security Assistant  ğŸ›¡ï¸            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                              â•‘
â•‘  I help you manage and troubleshoot SafeLine WAF.            â•‘
â•‘                                                              â•‘
â•‘  I can:                                                      â•‘
â•‘  ğŸ“Š Monitor traffic and stats                                â•‘
â•‘  ğŸ” Analyze attack logs                                      â•‘
â•‘  âš™ï¸  Configure WAF settings                                  â•‘
â•‘  ğŸ•µï¸  Look up threat intelligence                              â•‘
â•‘  ğŸ”§ Tune rules and fix false positives                       â•‘
â•‘  ğŸ“‹ Generate incident reports                                â•‘
â•‘  ğŸ“š Answer questions from documentation                      â•‘
â•‘                                                              â•‘
â•‘  Type 'quit' or 'exit' to leave.                             â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""


def run_chat():
    """Run the interactive chat loop."""
    print(WELCOME_BANNER)

    # Build the assistant graph
    print("â³ Loading AI assistant...")
    try:
        graph = build_assistant_graph()
        print("âœ… Assistant ready!\n")
    except Exception as e:
        print(f"âŒ Failed to initialize assistant: {e}")
        print("   Make sure LLM_PROVIDER and API keys are set in .env")
        return

    while True:
        try:
            user_input = input("ğŸ‘· Engineer: ").strip()
        except (KeyboardInterrupt, EOFError):
            print("\n\nğŸ‘‹ Goodbye!")
            break

        if not user_input:
            continue

        if user_input.lower() in ("quit", "exit", "q"):
            print("\nğŸ‘‹ Goodbye!")
            break

        # Invoke the graph
        print()
        try:
            state = {
                "messages": [HumanMessage(content=user_input)],
                "next_node": "",
                "context": {},
            }
            result = graph.invoke(state)

            # Extract the assistant's response
            if result["messages"]:
                last_msg = result["messages"][-1]
                print(f"ğŸ¤– Assistant: {last_msg.content}")
            else:
                print("ğŸ¤– Assistant: I couldn't process that request. Please try again.")

        except Exception as e:
            print(f"ğŸ¤– Assistant: âŒ Error processing your request: {e}")
            print("   This may be due to SafeLine API connectivity or LLM issues.")

        print()


if __name__ == "__main__":
    run_chat()
